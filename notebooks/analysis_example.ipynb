{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f8f63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo dos gr√°ficos\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"üìä Notebook de An√°lise - Sistema de P√¢ncreas Artificial\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚ö†Ô∏è  SISTEMA EXPERIMENTAL - APENAS PARA PESQUISA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# C√©lula 2: Fun√ß√£o para carregar dados\n",
    "def load_simulation_data(csv_files=None):\n",
    "    \"\"\"\n",
    "    Carrega dados de simula√ß√£o de arquivos CSV ou gera dados sint√©ticos\n",
    "    \n",
    "    Args:\n",
    "        csv_files: Lista de arquivos CSV para carregar\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame com dados de simula√ß√£o\n",
    "    \"\"\"\n",
    "    if csv_files is None:\n",
    "        print(\"üìÑ Gerando dados sint√©ticos para demonstra√ß√£o...\")\n",
    "        return generate_synthetic_data()\n",
    "    \n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            dfs.append(df)\n",
    "            print(f\"‚úÖ Carregado: {file} ({len(df)} registros)\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå Arquivo n√£o encontrado: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao carregar {file}: {e}\")\n",
    "    \n",
    "    if dfs:\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        combined_df = combined_df.sort_values('timestamp').reset_index(drop=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        return generate_synthetic_data()\n",
    "\n",
    "def generate_synthetic_data(days=7):\n",
    "    \"\"\"Gera dados sint√©ticos realistas para demonstra√ß√£o\"\"\"\n",
    "    \n",
    "    # Par√¢metros da simula√ß√£o\n",
    "    start_time = datetime.now() - timedelta(days=days)\n",
    "    timestep_minutes = 10\n",
    "    total_points = days * 24 * 6  # 6 pontos por hora\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i in range(total_points):\n",
    "        timestamp = start_time + timedelta(minutes=i * timestep_minutes)\n",
    "        hour = timestamp.hour\n",
    "        day_of_week = timestamp.weekday()\n",
    "        \n",
    "        # Modelo circadiano de glicemia\n",
    "        circadian_base = 120\n",
    "        dawn_effect = 15 * np.sin(2 * np.pi * (hour - 6) / 24)  # Dawn phenomenon\n",
    "        weekly_variation = 5 * np.sin(2 * np.pi * day_of_week / 7)\n",
    "        \n",
    "        # Ru√≠do e variabilidade individual\n",
    "        noise = np.random.normal(0, 12)\n",
    "        \n",
    "        # Eventos de refei√ß√£o (probabil√≠sticos)\n",
    "        meal_effect = 0\n",
    "        if hour in [7, 12, 19] and np.random.random() < 0.7:  # Refei√ß√µes principais\n",
    "            meal_magnitude = np.random.uniform(30, 80)\n",
    "            meal_duration = np.random.uniform(90, 180)  # minutos\n",
    "            time_since_meal = (i % (meal_duration // timestep_minutes)) * timestep_minutes\n",
    "            \n",
    "            if time_since_meal <= meal_duration:\n",
    "                # Curva de absor√ß√£o tipo log-normal\n",
    "                peak_time = meal_duration * 0.3\n",
    "                meal_effect = meal_magnitude * np.exp(-(np.log(time_since_meal + 1) - np.log(peak_time))**2 / (2 * 0.5**2))\n",
    "        \n",
    "        # Efeito de exerc√≠cio (ocasional)\n",
    "        exercise_effect = 0\n",
    "        if hour in [17, 18, 19] and np.random.random() < 0.2:  # Exerc√≠cio √† tarde\n",
    "            exercise_effect = -np.random.uniform(20, 40)\n",
    "        \n",
    "        # Glicemia final\n",
    "        glucose = max(60, min(350, \n",
    "            circadian_base + dawn_effect + weekly_variation + \n",
    "            meal_effect + exercise_effect + noise\n",
    "        ))\n",
    "        \n",
    "        # Calcular dose de insulina baseada em controlador simples\n",
    "        target_glucose = 120\n",
    "        error = glucose - target_glucose\n",
    "        \n",
    "        # PID simplificado\n",
    "        kp = 0.05\n",
    "        insulin_dose = max(0, kp * error / 100)  # Converter para unidades apropriadas\n",
    "        \n",
    "        # Adicionar ru√≠do na dose\n",
    "        if insulin_dose > 0:\n",
    "            insulin_dose += np.random.normal(0, 0.1)\n",
    "            insulin_dose = max(0, insulin_dose)\n",
    "        \n",
    "        # Determinar tipo de dose\n",
    "        if meal_effect > 20:\n",
    "            dose_type = 'bolus'\n",
    "        elif insulin_dose > 0.5:\n",
    "            dose_type = 'correction'\n",
    "        else:\n",
    "            dose_type = 'basal'\n",
    "        \n",
    "        # Simular confian√ßa do sistema\n",
    "        confidence = min(1.0, 0.5 + (days - abs(i / (total_points / days) - days/2)) / days)\n",
    "        confidence += np.random.normal(0, 0.1)\n",
    "        confidence = max(0.1, min(0.95, confidence))\n",
    "        \n",
    "        # Simular componentes PID e ML\n",
    "        pid_component = insulin_dose * 0.8\n",
    "        ml_component = insulin_dose * 0.2 * confidence\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'step': i,\n",
    "            'glucose': glucose,\n",
    "            'insulin_dose': insulin_dose,\n",
    "            'dose_type': dose_type,\n",
    "            'confidence': confidence,\n",
    "            'pid_component': pid_component,\n",
    "            'ml_component': ml_component,\n",
    "            'hour_of_day': hour,\n",
    "            'day_of_week': day_of_week,\n",
    "            'meal_effect': meal_effect,\n",
    "            'exercise_effect': exercise_effect\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"üìä Dados sint√©ticos gerados: {len(df)} pontos ({days} dias)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# C√©lula 3: Carregar dados\n",
    "# Exemplo de uso - substituir pelos seus arquivos CSV reais\n",
    "csv_files = [\n",
    "    # 'exports/simulation_data_20241210.csv',\n",
    "    # 'exports/controller_decisions_20241210.csv'\n",
    "]\n",
    "\n",
    "df = load_simulation_data(csv_files)\n",
    "print(f\"\\nüìà Dataset carregado: {len(df)} registros\")\n",
    "print(f\"üìÖ Per√≠odo: {df['timestamp'].min()} at√© {df['timestamp'].max()}\")\n",
    "print(f\"‚è±Ô∏è Dura√ß√£o: {(df['timestamp'].max() - df['timestamp'].min()).days} dias\")\n",
    "\n",
    "# C√©lula 4: An√°lise explorat√≥ria b√°sica\n",
    "def basic_statistics(df):\n",
    "    \"\"\"Calcula estat√≠sticas b√°sicas do dataset\"\"\"\n",
    "    \n",
    "    print(\"üìä ESTAT√çSTICAS B√ÅSICAS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Estat√≠sticas de glicemia\n",
    "    glucose_stats = df['glucose'].describe()\n",
    "    print(f\"Glicemia (mg/dL):\")\n",
    "    print(f\"  M√©dia: {glucose_stats['mean']:.1f}\")\n",
    "    print(f\"  Mediana: {glucose_stats['50%']:.1f}\")\n",
    "    print(f\"  Desvio padr√£o: {glucose_stats['std']:.1f}\")\n",
    "    print(f\"  Min: {glucose_stats['min']:.1f}\")\n",
    "    print(f\"  Max: {glucose_stats['max']:.1f}\")\n",
    "    \n",
    "    # Tempo em faixa\n",
    "    in_range = ((df['glucose'] >= 70) & (df['glucose'] <= 180)).sum()\n",
    "    below_range = (df['glucose'] < 70).sum()\n",
    "    above_range = (df['glucose'] > 180).sum()\n",
    "    total = len(df)\n",
    "    \n",
    "    print(f\"\\nTempo em Faixa:\")\n",
    "    print(f\"  70-180 mg/dL: {in_range/total*100:.1f}%\")\n",
    "    print(f\"  < 70 mg/dL: {below_range/total*100:.1f}%\")\n",
    "    print(f\"  > 180 mg/dL: {above_range/total*100:.1f}%\")\n",
    "    \n",
    "    # Estat√≠sticas de insulina\n",
    "    insulin_stats = df['insulin_dose'].describe()\n",
    "    print(f\"\\nInsulina (U):\")\n",
    "    print(f\"  Total di√°rio m√©dio: {insulin_stats['mean']*24*6:.1f}\")\n",
    "    print(f\"  Dose m√°xima: {insulin_stats['max']:.2f}\")\n",
    "    print(f\"  Doses > 0: {(df['insulin_dose'] > 0).sum()}\")\n",
    "    \n",
    "    return {\n",
    "        'glucose_mean': glucose_stats['mean'],\n",
    "        'glucose_std': glucose_stats['std'],\n",
    "        'time_in_range': in_range/total,\n",
    "        'time_below': below_range/total,\n",
    "        'time_above': above_range/total,\n",
    "        'daily_insulin': insulin_stats['mean']*24*6\n",
    "    }\n",
    "\n",
    "stats = basic_statistics(df)\n",
    "\n",
    "# C√©lula 5: Visualiza√ß√µes principais\n",
    "def create_glucose_timeline(df, days_to_show=3):\n",
    "    \"\"\"Cria gr√°fico de timeline de glicemia interativo\"\"\"\n",
    "    \n",
    "    # Filtrar √∫ltimos N dias para visualiza√ß√£o\n",
    "    end_date = df['timestamp'].max()\n",
    "    start_date = end_date - timedelta(days=days_to_show)\n",
    "    df_filtered = df[df['timestamp'] >= start_date].copy()\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        subplot_titles=['Glicemia (mg/dL)', 'Insulina (U)', 'Confian√ßa do Sistema'],\n",
    "        vertical_spacing=0.08,\n",
    "        row_heights=[0.5, 0.25, 0.25]\n",
    "    )\n",
    "    \n",
    "    # Gr√°fico principal de glicemia\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_filtered['timestamp'],\n",
    "            y=df_filtered['glucose'],\n",
    "            mode='lines',\n",
    "            name='Glicemia',\n",
    "            line=dict(color='blue', width=2),\n",
    "            hovertemplate='%{x}<br>Glicemia: %{y:.1f} mg/dL<extra></extra>'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Zonas de refer√™ncia\n",
    "    fig.add_hline(y=70, line_dash=\"dash\", line_color=\"orange\", \n",
    "                  annotation_text=\"Limite inferior (70)\", row=1, col=1)\n",
    "    fig.add_hline(y=180, line_dash=\"dash\", line_color=\"red\", \n",
    "                  annotation_text=\"Limite superior (180)\", row=1, col=1)\n",
    "    fig.add_hline(y=120, line_dash=\"dot\", line_color=\"green\", \n",
    "                  annotation_text=\"Alvo (120)\", row=1, col=1)\n",
    "    \n",
    "    # Gr√°fico de insulina\n",
    "    colors = {'basal': 'lightblue', 'bolus': 'orange', 'correction': 'red'}\n",
    "    for dose_type in df_filtered['dose_type'].unique():\n",
    "        mask = df_filtered['dose_type'] == dose_type\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_filtered[mask]['timestamp'],\n",
    "                y=df_filtered[mask]['insulin_dose'],\n",
    "                mode='markers',\n",
    "                name=f'Insulina {dose_type}',\n",
    "                marker=dict(color=colors.get(dose_type, 'gray'), size=6),\n",
    "                hovertemplate=f'{dose_type}: %{{y:.2f}}U<br>%{{x}}<extra></extra>'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # Gr√°fico de confian√ßa\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_filtered['timestamp'],\n",
    "            y=df_filtered['confidence'],\n",
    "            mode='lines',\n",
    "            name='Confian√ßa',\n",
    "            line=dict(color='purple', width=2),\n",
    "            fill='tonexty',\n",
    "            hovertemplate='Confian√ßa: %{y:.1%}<extra></extra>'\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Timeline do Sistema APS - √öltimos {days_to_show} dias\",\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Configurar eixos\n",
    "    fig.update_yaxes(title_text=\"mg/dL\", row=1, col=1, range=[50, 300])\n",
    "    fig.update_yaxes(title_text=\"Unidades\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Confian√ßa\", row=3, col=1, range=[0, 1], tickformat='.0%')\n",
    "    fig.update_xaxes(title_text=\"Data/Hora\", row=3, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Criar e exibir gr√°fico\n",
    "fig_timeline = create_glucose_timeline(df, days_to_show=3)\n",
    "fig_timeline.show()\n",
    "\n",
    "# C√©lula 6: An√°lise de padr√µes circadianos\n",
    "def analyze_circadian_patterns(df):\n",
    "    \"\"\"Analisa padr√µes circadianos na glicemia\"\"\"\n",
    "    \n",
    "    # Agrupar por hora do dia\n",
    "    hourly_stats = df.groupby('hour_of_day').agg({\n",
    "        'glucose': ['mean', 'std', 'count'],\n",
    "        'insulin_dose': 'sum'\n",
    "    }).round(2)\n",
    "    \n",
    "    hourly_stats.columns = ['glucose_mean', 'glucose_std', 'count', 'total_insulin']\n",
    "    hourly_stats = hourly_stats.reset_index()\n",
    "    \n",
    "    # Criar gr√°fico circadiano\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=['Glicemia M√©dia por Hora', 'Insulina Total por Hora'],\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # Glicemia m√©dia com banda de erro\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=hourly_stats['hour_of_day'],\n",
    "            y=hourly_stats['glucose_mean'],\n",
    "            mode='lines+markers',\n",
    "            name='Glicemia m√©dia',\n",
    "            line=dict(color='blue', width=3),\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                array=hourly_stats['glucose_std'],\n",
    "                visible=True,\n",
    "                color='lightblue'\n",
    "            )\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Insulina total por hora\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=hourly_stats['hour_of_day'],\n",
    "            y=hourly_stats['total_insulin'],\n",
    "            name='Insulina total',\n",
    "            marker_color='orange',\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Padr√µes Circadianos\",\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Hora do Dia\", dtick=2)\n",
    "    fig.update_yaxes(title_text=\"Glicemia (mg/dL)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Insulina Total (U)\", row=2, col=1)\n",
    "    \n",
    "    return fig, hourly_stats\n",
    "\n",
    "fig_circadian, hourly_data = analyze_circadian_patterns(df)\n",
    "fig_circadian.show()\n",
    "\n",
    "# Identificar padr√µes\n",
    "dawn_effect = hourly_data[hourly_data['hour_of_day'].between(4, 8)]['glucose_mean'].max() - \\\n",
    "              hourly_data[hourly_data['hour_of_day'].between(4, 8)]['glucose_mean'].min()\n",
    "\n",
    "print(f\"üìà Dawn Phenomenon detectado: {dawn_effect:.1f} mg/dL de varia√ß√£o matinal\")\n",
    "\n",
    "# C√©lula 7: An√°lise de efic√°cia do controlador\n",
    "def analyze_controller_performance(df):\n",
    "    \"\"\"Analisa desempenho do controlador h√≠brido\"\"\"\n",
    "    \n",
    "    # Calcular correla√ß√£o entre componentes\n",
    "    corr_pid_ml = df['pid_component'].corr(df['ml_component'])\n",
    "    \n",
    "    # Analisar evolu√ß√£o da confian√ßa ao longo do tempo\n",
    "    df['days_from_start'] = (df['timestamp'] - df['timestamp'].min()).dt.total_seconds() / (24 * 3600)\n",
    "    \n",
    "    # Regress√£o linear da confian√ßa ao longo do tempo\n",
    "    from scipy import stats\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(df['days_from_start'], df['confidence'])\n",
    "    \n",
    "    print(\"ü§ñ AN√ÅLISE DO CONTROLADOR\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Correla√ß√£o PID-ML: {corr_pid_ml:.3f}\")\n",
    "    print(f\"Evolu√ß√£o da confian√ßa: {slope:.3f}/dia (R¬≤={r_value**2:.3f})\")\n",
    "    \n",
    "    # Gr√°fico de evolu√ß√£o da confian√ßa\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['timestamp'],\n",
    "            y=df['confidence'],\n",
    "            mode='markers',\n",
    "            name='Confian√ßa',\n",
    "            marker=dict(color='purple', size=4, opacity=0.6)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Linha de tend√™ncia\n",
    "    trend_y = slope * df['days_from_start'] + intercept\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['timestamp'],\n",
    "            y=trend_y,\n",
    "            mode='lines',\n",
    "            name='Tend√™ncia',\n",
    "            line=dict(color='red', width=2, dash='dash')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Evolu√ß√£o da Confian√ßa do Sistema\",\n",
    "        xaxis_title=\"Tempo\",\n",
    "        yaxis_title=\"Confian√ßa\",\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(tickformat='.0%')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig_confidence = analyze_controller_performance(df)\n",
    "fig_confidence.show()\n",
    "\n",
    "# C√©lula 8: Detec√ß√£o de eventos adversos\n",
    "def detect_adverse_events(df):\n",
    "    \"\"\"Detecta e analisa eventos adversos\"\"\"\n",
    "    \n",
    "    events = []\n",
    "    \n",
    "    # Detectar hipoglicemias (< 70 mg/dL por > 15 min)\n",
    "    hypo_mask = df['glucose'] < 70\n",
    "    \n",
    "    # Detectar sequ√™ncias cont√≠nuas\n",
    "    hypo_sequences = []\n",
    "    in_hypo = False\n",
    "    start_idx = None\n",
    "    \n",
    "    for i, is_hypo in enumerate(hypo_mask):\n",
    "        if is_hypo and not in_hypo:\n",
    "            in_hypo = True\n",
    "            start_idx = i\n",
    "        elif not is_hypo and in_hypo:\n",
    "            in_hypo = False\n",
    "            duration_min = (i - start_idx) * 10  # 10 min por ponto\n",
    "            if duration_min >= 15:\n",
    "                hypo_sequences.append({\n",
    "                    'start': start_idx,\n",
    "                    'end': i-1,\n",
    "                    'duration_min': duration_min,\n",
    "                    'min_glucose': df.iloc[start_idx:i]['glucose'].min()\n",
    "                })\n",
    "    \n",
    "    # Detectar hiperglicemias prolongadas (> 250 mg/dL por > 2h)\n",
    "    hyper_mask = df['glucose'] > 250\n",
    "    \n",
    "    hyper_sequences = []\n",
    "    in_hyper = False\n",
    "    start_idx = None\n",
    "    \n",
    "    for i, is_hyper in enumerate(hyper_mask):\n",
    "        if is_hyper and not in_hyper:\n",
    "            in_hyper = True\n",
    "            start_idx = i\n",
    "        elif not is_hyper and in_hyper:\n",
    "            in_hyper = False\n",
    "            duration_min = (i - start_idx) * 10\n",
    "            if duration_min >= 120:  # 2 horas\n",
    "                hyper_sequences.append({\n",
    "                    'start': start_idx,\n",
    "                    'end': i-1,\n",
    "                    'duration_min': duration_min,\n",
    "                    'max_glucose': df.iloc[start_idx:i]['glucose'].max()\n",
    "                })\n",
    "    \n",
    "    print(\"üö® EVENTOS ADVERSOS DETECTADOS\")\n",
    "    print(\"=\"*35)\n",
    "    print(f\"Hipoglicemias (‚â•15 min): {len(hypo_sequences)}\")\n",
    "    for i, event in enumerate(hypo_sequences[:5], 1):  # Mostrar at√© 5\n",
    "        timestamp = df.iloc[event['start']]['timestamp']\n",
    "        print(f\"  {i}. {timestamp}: {event['duration_min']} min, m√≠n {event['min_glucose']:.1f} mg/dL\")\n",
    "    \n",
    "    print(f\"\\nHiperglicemias (‚â•2h): {len(hyper_sequences)}\")\n",
    "    for i, event in enumerate(hyper_sequences[:5], 1):\n",
    "        timestamp = df.iloc[event['start']]['timestamp']\n",
    "        print(f\"  {i}. {timestamp}: {event['duration_min']} min, m√°x {event['max_glucose']:.1f} mg/dL\")\n",
    "    \n",
    "    return hypo_sequences, hyper_sequences\n",
    "\n",
    "hypo_events, hyper_events = detect_adverse_events(df)\n",
    "\n",
    "# C√©lula 9: M√©tricas avan√ßadas de qualidade\n",
    "def calculate_advanced_metrics(df):\n",
    "    \"\"\"Calcula m√©tricas avan√ßadas de qualidade\"\"\"\n",
    "    \n",
    "    glucose_values = df['glucose'].values\n",
    "    \n",
    "    # GMI (Glucose Management Indicator) - estimativa de HbA1c\n",
    "    mean_glucose = np.mean(glucose_values)\n",
    "    gmi = 3.31 + 0.02392 * mean_glucose\n",
    "    \n",
    "    # Coeficiente de Varia√ß√£o\n",
    "    cv = (np.std(glucose_values) / mean_glucose) * 100\n",
    "    \n",
    "    # MAGE (Mean Amplitude of Glycemic Excursions)\n",
    "    # Simplificado: desvio padr√£o das diferen√ßas\n",
    "    glucose_diff = np.diff(glucose_values)\n",
    "    mage = np.std(glucose_diff[np.abs(glucose_diff) > np.std(glucose_values)])\n",
    "    \n",
    "    # J-Index (combina√ß√£o de m√©dia e variabilidade)\n",
    "    j_index = 0.001 * (mean_glucose + np.std(glucose_values))**2\n",
    "    \n",
    "    # CONGA (Continuous Overall Net Glycemic Action)\n",
    "    # Desvio padr√£o das diferen√ßas a cada hora (6 pontos)\n",
    "    if len(glucose_values) >= 6:\n",
    "        hourly_diffs = [glucose_values[i] - glucose_values[i-6] \n",
    "                       for i in range(6, len(glucose_values))]\n",
    "        conga = np.std(hourly_diffs) if hourly_diffs else 0\n",
    "    else:\n",
    "        conga = 0\n",
    "    \n",
    "    # GRADE (Glycemic Risk Assessment Diabetes Equation)\n",
    "    # Transforma√ß√£o logar√≠tmica dos valores de glucose\n",
    "    glucose_mmol = glucose_values / 18.0  # Converter para mmol/L\n",
    "    log_glucose = np.log(glucose_mmol)\n",
    "    transformed = 1.509 * (log_glucose**1.084 - 5.381)\n",
    "    grade = np.mean(transformed**2)\n",
    "    \n",
    "    metrics = {\n",
    "        'GMI (%)': round(gmi, 1),\n",
    "        'CV (%)': round(cv, 1),\n",
    "        'MAGE': round(mage, 1),\n",
    "        'J-Index': round(j_index, 3),\n",
    "        'CONGA': round(conga, 1),\n",
    "        'GRADE': round(grade, 2)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "advanced_metrics = calculate_advanced_metrics(df)\n",
    "\n",
    "print(\"üìä M√âTRICAS AVAN√áADAS DE QUALIDADE\")\n",
    "print(\"=\"*40)\n",
    "for metric, value in advanced_metrics.items():\n",
    "    print(f\"{metric:15}: {value}\")\n",
    "\n",
    "# Interpreta√ß√£o das m√©tricas\n",
    "print(\"\\nüí° INTERPRETA√á√ÉO:\")\n",
    "if advanced_metrics['GMI (%)'] <= 7.0:\n",
    "    print(\"‚úÖ GMI excelente (‚â§7%)\")\n",
    "elif advanced_metrics['GMI (%)'] <= 8.0:\n",
    "    print(\"‚ö†Ô∏è GMI moderado (7-8%)\")\n",
    "else:\n",
    "    print(\"üö® GMI elevado (>8%)\")\n",
    "\n",
    "if advanced_metrics['CV (%)'] <= 36:\n",
    "    print(\"‚úÖ Baixa variabilidade glic√™mica (CV ‚â§36%)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Alta variabilidade glic√™mica (CV >36%)\")\n",
    "\n",
    "# C√©lula 10: Compara√ß√£o com benchmarks\n",
    "def compare_with_benchmarks(df):\n",
    "    \"\"\"Compara m√©tricas com benchmarks cl√≠nicos\"\"\"\n",
    "    \n",
    "    # Benchmarks da literatura para sistemas CGM\n",
    "    benchmarks = {\n",
    "        'Excelente': {'TIR': 0.80, 'TBR': 0.02, 'TAR': 0.18, 'CV': 30},\n",
    "        'Bom': {'TIR': 0.70, 'TBR': 0.04, 'TAR': 0.26, 'CV': 36},\n",
    "        'Moderado': {'TIR': 0.60, 'TBR': 0.06, 'TAR': 0.34, 'CV': 42},\n",
    "        'Inadequado': {'TIR': 0.50, 'TBR': 0.10, 'TAR': 0.40, 'CV': 50}\n",
    "    }\n",
    "    \n",
    "    # Calcular m√©tricas atuais\n",
    "    tir = ((df['glucose'] >= 70) & (df['glucose'] <= 180)).mean()\n",
    "    tbr = (df['glucose'] < 70).mean()\n",
    "    tar = (df['glucose'] > 180).mean()\n",
    "    cv = (df['glucose'].std() / df['glucose'].mean()) * 100\n",
    "    \n",
    "    current_metrics = {'TIR': tir, 'TBR': tbr, 'TAR': tar, 'CV': cv}\n",
    "    \n",
    "    # Determinar classifica√ß√£o\n",
    "    classification = 'Inadequado'\n",
    "    for level in ['Excelente', 'Bom', 'Moderado']:\n",
    "        if (tir >= benchmarks[level]['TIR'] and \n",
    "            tbr <= benchmarks[level]['TBR'] and\n",
    "            cv <= benchmarks[level]['CV']):\n",
    "            classification = level\n",
    "            break\n",
    "    \n",
    "    print(\"üéØ COMPARA√á√ÉO COM BENCHMARKS CL√çNICOS\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # Criar tabela de compara√ß√£o\n",
    "    comparison_data = []\n",
    "    for level, bench in benchmarks.items():\n",
    "        comparison_data.append({\n",
    "            'Classifica√ß√£o': level,\n",
    "            'TIR_bench': f\"{bench['TIR']:.0%}\",\n",
    "            'TBR_bench': f\"{bench['TBR']:.0%}\",\n",
    "            'CV_bench': f\"{bench['CV']:.0f}%\",\n",
    "            'Status': '‚úÖ' if level == classification else ''\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nüèÜ CLASSIFICA√á√ÉO ATUAL: {classification}\")\n",
    "    print(f\"   TIR: {tir:.0%} | TBR: {tbr:.0%} | CV: {cv:.0f}%\")\n",
    "    \n",
    "    # Sugest√µes de melhoria\n",
    "    print(f\"\\nüí° SUGEST√ïES PARA PR√ìXIMO N√çVEL:\")\n",
    "    if classification != 'Excelente':\n",
    "        next_levels = ['Moderado', 'Bom', 'Excelente']\n",
    "        try:\n",
    "            current_idx = next_levels.index(classification)\n",
    "            next_level = next_levels[current_idx + 1] if current_idx < len(next_levels) - 1 else 'Excelente'\n",
    "        except ValueError:\n",
    "            next_level = 'Moderado'\n",
    "        \n",
    "        target = benchmarks[next_level]\n",
    "        \n",
    "        if tir < target['TIR']:\n",
    "            print(f\"   ‚Ä¢ Aumentar TIR para {target['TIR']:.0%} (+{(target['TIR']-tir)*100:.1f}pp)\")\n",
    "        if tbr > target['TBR']:\n",
    "            print(f\"   ‚Ä¢ Reduzir TBR para {target['TBR']:.0%} (-{(tbr-target['TBR'])*100:.1f}pp)\")\n",
    "        if cv > target['CV']:\n",
    "            print(f\"   ‚Ä¢ Reduzir CV para {target['CV']:.0f}% (-{cv-target['CV']:.1f}pp)\")\n",
    "\n",
    "compare_with_benchmarks(df)\n",
    "\n",
    "# C√©lula 11: Relat√≥rio executivo automatizado\n",
    "def generate_executive_report(df):\n",
    "    \"\"\"Gera relat√≥rio executivo automatizado\"\"\"\n",
    "    \n",
    "    # Calcular todas as m√©tricas necess√°rias\n",
    "    duration_days = (df['timestamp'].max() - df['timestamp'].min()).days\n",
    "    total_readings = len(df)\n",
    "    \n",
    "    # M√©tricas b√°sicas\n",
    "    tir = ((df['glucose'] >= 70) & (df['glucose'] <= 180)).mean()\n",
    "    mean_glucose = df['glucose'].mean()\n",
    "    cv = (df['glucose'].std() / mean_glucose) * 100\n",
    "    \n",
    "    # Eventos adversos\n",
    "    hypo_events = len([1 for i in range(len(df)-1) \n",
    "                      if df.iloc[i]['glucose'] < 70 and df.iloc[i+1]['glucose'] < 70])\n",
    "    \n",
    "    # Insulina\n",
    "    total_insulin = df['insulin_dose'].sum()\n",
    "    avg_daily_insulin = total_insulin / duration_days if duration_days > 0 else 0\n",
    "    \n",
    "    # Confian√ßa do sistema\n",
    "    avg_confidence = df['confidence'].mean()\n",
    "    final_confidence = df['confidence'].tail(100).mean()  # √öltimas leituras\n",
    "    \n",
    "    # Status geral baseado em m√©tricas\n",
    "    if tir >= 0.7 and cv <= 36 and hypo_events == 0:\n",
    "        status = \"üü¢ EXCELENTE\"\n",
    "    elif tir >= 0.6 and cv <= 42:\n",
    "        status = \"üü° BOM\"\n",
    "    elif tir >= 0.5:\n",
    "        status = \"üü† MODERADO\"\n",
    "    else:\n",
    "        status = \"üî¥ NECESSITA AJUSTES\"\n",
    "    \n",
    "    report = f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                  RELAT√ìRIO EXECUTIVO - SISTEMA APS               ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "üìä RESUMO GERAL\n",
    "{'='*50}\n",
    "Status do Sistema: {status}\n",
    "Per√≠odo Analisado: {duration_days} dias ({total_readings:,} leituras)\n",
    "√öltima Atualiza√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n",
    "\n",
    "üéØ M√âTRICAS PRINCIPAIS\n",
    "{'='*50}\n",
    "‚Ä¢ Tempo em Faixa (70-180): {tir:.1%} {'‚úÖ' if tir >= 0.7 else '‚ö†Ô∏è' if tir >= 0.6 else 'üö®'}\n",
    "‚Ä¢ Glicemia M√©dia: {mean_glucose:.0f} mg/dL {'‚úÖ' if 100 <= mean_glucose <= 154 else '‚ö†Ô∏è'}\n",
    "‚Ä¢ Variabilidade (CV): {cv:.0f}% {'‚úÖ' if cv <= 36 else '‚ö†Ô∏è' if cv <= 42 else 'üö®'}\n",
    "‚Ä¢ Eventos de Hipoglicemia: {hypo_events} {'‚úÖ' if hypo_events == 0 else 'üö®'}\n",
    "\n",
    "üíâ USO DE INSULINA\n",
    "{'='*50}\n",
    "‚Ä¢ Total do Per√≠odo: {total_insulin:.1f} U\n",
    "‚Ä¢ M√©dia Di√°ria: {avg_daily_insulin:.1f} U/dia\n",
    "‚Ä¢ Efici√™ncia: {mean_glucose/avg_daily_insulin if avg_daily_insulin > 0 else 0:.1f} mg/dL por U/dia\n",
    "\n",
    "ü§ñ DESEMPENHO DO SISTEMA\n",
    "{'='*50}\n",
    "‚Ä¢ Confian√ßa M√©dia: {avg_confidence:.1%}\n",
    "‚Ä¢ Confian√ßa Atual: {final_confidence:.1%}\n",
    "‚Ä¢ Evolu√ß√£o: {'üìà Melhorando' if final_confidence > avg_confidence else 'üìâ Estabilizando'}\n",
    "\n",
    "üéØ RECOMENDA√á√ïES PRIORIT√ÅRIAS\n",
    "{'='*50}\"\"\"\n",
    "\n",
    "    # Adicionar recomenda√ß√µes baseadas nas m√©tricas\n",
    "    recommendations = []\n",
    "    \n",
    "    if tir < 0.7:\n",
    "        recommendations.append(\"‚Ä¢ PRIORIDADE ALTA: Melhorar tempo em faixa alvo\")\n",
    "    \n",
    "    if cv > 36:\n",
    "        recommendations.append(\"‚Ä¢ Reduzir variabilidade glic√™mica - ajustar par√¢metros PID\")\n",
    "    \n",
    "    if hypo_events > 0:\n",
    "        recommendations.append(\"‚Ä¢ CR√çTICO: Implementar melhor preven√ß√£o de hipoglicemia\")\n",
    "    \n",
    "    if avg_daily_insulin > 100:\n",
    "        recommendations.append(\"‚Ä¢ Revisar configura√ß√µes de sensibilidade √† insulina\")\n",
    "    \n",
    "    if final_confidence < 0.8:\n",
    "        recommendations.append(\"‚Ä¢ Continuar per√≠odo de adapta√ß√£o do sistema ML\")\n",
    "    \n",
    "    if not recommendations:\n",
    "        recommendations.append(\"‚Ä¢ Sistema operando dentro dos par√¢metros adequados\")\n",
    "        recommendations.append(\"‚Ä¢ Manter monitoramento e ajustes finos\")\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        report += f\"\\n{rec}\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "\n",
    "üìà PR√ìXIMOS PASSOS\n",
    "{'='*50}\n",
    "1. An√°lise detalhada dos padr√µes circadianos\n",
    "2. Otimiza√ß√£o dos par√¢metros do controlador h√≠brido\n",
    "3. Valida√ß√£o em cen√°rios de estresse (refei√ß√µes grandes, exerc√≠cios)\n",
    "4. Compara√ß√£o com sistemas APS comerciais\n",
    "\n",
    "‚ö†Ô∏è  DISCLAIMER\n",
    "{'='*50}\n",
    "Este relat√≥rio √© baseado em dados de simula√ß√£o para fins de pesquisa.\n",
    "N√ÉO utilizar para decis√µes cl√≠nicas sem valida√ß√£o m√©dica adequada.\n",
    "\n",
    "Gerado automaticamente pelo Sistema APS v1.0\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Gerar e exibir relat√≥rio\n",
    "executive_report = generate_executive_report(df)\n",
    "print(executive_report)\n",
    "\n",
    "# C√©lula 12: Exporta√ß√£o de dados e gr√°ficos\n",
    "def export_analysis_results(df, stats, advanced_metrics):\n",
    "    \"\"\"Exporta resultados da an√°lise\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Exportar dataset processado\n",
    "    df_export = df.copy()\n",
    "    df_export['date'] = df_export['timestamp'].dt.date\n",
    "    df_export['time'] = df_export['timestamp'].dt.time\n",
    "    \n",
    "    filename_data = f'analysis_data_{timestamp}.csv'\n",
    "    df_export.to_csv(filename_data, index=False)\n",
    "    print(f\"üìÅ Dataset exportado: {filename_data}\")\n",
    "    \n",
    "    # Exportar m√©tricas consolidadas\n",
    "    metrics_summary = {\n",
    "        **stats,\n",
    "        **advanced_metrics,\n",
    "        'analysis_timestamp': datetime.now().isoformat(),\n",
    "        'data_period_days': (df['timestamp'].max() - df['timestamp'].min()).days,\n",
    "        'total_readings': len(df)\n",
    "    }\n",
    "    \n",
    "    filename_metrics = f'metrics_summary_{timestamp}.json'\n",
    "    import json\n",
    "    with open(filename_metrics, 'w') as f:\n",
    "        json.dump(metrics_summary, f, indent=2, default=str)\n",
    "    print(f\"üìä M√©tricas exportadas: {filename_metrics}\")\n",
    "    \n",
    "    # Criar relat√≥rio HTML\n",
    "    html_report = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Relat√≥rio de An√°lise APS</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "            .metric {{ margin: 10px 0; padding: 10px; border-left: 4px solid #007bff; }}\n",
    "            .excellent {{ border-left-color: #28a745; }}\n",
    "            .warning {{ border-left-color: #ffc107; }}\n",
    "            .danger {{ border-left-color: #dc3545; }}\n",
    "            pre {{ background: #f8f9fa; padding: 15px; border-radius: 5px; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Relat√≥rio de An√°lise - Sistema de P√¢ncreas Artificial</h1>\n",
    "        <p>Gerado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}</p>\n",
    "        \n",
    "        <h2>Resumo Executivo</h2>\n",
    "        <pre>{executive_report}</pre>\n",
    "        \n",
    "        <h2>M√©tricas Detalhadas</h2>\n",
    "        <div class=\"metric {'excellent' if stats['time_in_range'] >= 0.7 else 'warning' if stats['time_in_range'] >= 0.6 else 'danger'}\">\n",
    "            <strong>Tempo em Faixa:</strong> {stats['time_in_range']:.1%}\n",
    "        </div>\n",
    "        <div class=\"metric\">\n",
    "            <strong>Glicemia M√©dia:</strong> {stats['glucose_mean']:.1f} mg/dL\n",
    "        </div>\n",
    "        <div class=\"metric {'excellent' if advanced_metrics['CV (%)'] <= 36 else 'warning'}\">\n",
    "            <strong>Coeficiente de Varia√ß√£o:</strong> {advanced_metrics['CV (%)']}%\n",
    "        </div>\n",
    "        <div class=\"metric\">\n",
    "            <strong>GMI Estimado:</strong> {advanced_metrics['GMI (%)']}%\n",
    "        </div>\n",
    "        \n",
    "        <h2>An√°lise de Eventos</h2>\n",
    "        <p>Hipoglicemias detectadas: {len(hypo_events)}</p>\n",
    "        <p>Hiperglicemias detectadas: {len(hyper_events)}</p>\n",
    "        \n",
    "        <p><em>Relat√≥rio gerado automaticamente pelo sistema APS para fins de pesquisa.</em></p>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    filename_html = f'aps_report_{timestamp}.html'\n",
    "    with open(filename_html, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_report)\n",
    "    print(f\"üìÑ Relat√≥rio HTML: {filename_html}\")\n",
    "    \n",
    "    return {\n",
    "        'data_file': filename_data,\n",
    "        'metrics_file': filename_metrics,\n",
    "        'html_report': filename_html\n",
    "    }\n",
    "\n",
    "# Exportar resultados\n",
    "exported_files = export_analysis_results(df, stats, advanced_metrics)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úÖ AN√ÅLISE CONCLU√çDA COM SUCESSO!\n",
    "\n",
    "üìÅ Arquivos gerados:\n",
    "   ‚Ä¢ Dados: {exported_files['data_file']}\n",
    "   ‚Ä¢ M√©tricas: {exported_files['metrics_file']}  \n",
    "   ‚Ä¢ Relat√≥rio: {exported_files['html_report']}\n",
    "\n",
    "üî¨ Para an√°lises avan√ßadas:\n",
    "   ‚Ä¢ Use os gr√°ficos interativos acima\n",
    "   ‚Ä¢ Examine padr√µes circadianos\n",
    "   ‚Ä¢ Analise correla√ß√µes entre vari√°veis\n",
    "   ‚Ä¢ Compare diferentes per√≠odos\n",
    "\n",
    "‚ö†Ô∏è  LEMBRETE: Sistema experimental - apenas para pesquisa!\n",
    "\"\"\")\n",
    "\n",
    "# C√©lula final: Instru√ß√µes para pr√≥ximos passos\n",
    "print(\"\"\"\n",
    "üöÄ PR√ìXIMOS PASSOS SUGERIDOS:\n",
    "\n",
    "1. AN√ÅLISE TEMPORAL\n",
    "   ‚Ä¢ Examine tend√™ncias semanais e mensais\n",
    "   ‚Ä¢ Identifique padr√µes sazonais\n",
    "   ‚Ä¢ Analise impacto de mudan√ßas de configura√ß√£o\n",
    "\n",
    "2. OTIMIZA√á√ÉO DO CONTROLADOR\n",
    "   ‚Ä¢ Ajuste par√¢metros PID baseado nas m√©tricas\n",
    "   ‚Ä¢ Treine modelo ML com mais dados\n",
    "   ‚Ä¢ Teste diferentes estrat√©gias de controle\n",
    "\n",
    "3. VALIDA√á√ÉO CL√çNICA\n",
    "   ‚Ä¢ Compare com dados reais de CGM\n",
    "   ‚Ä¢ Valide algoritmos com especialistas\n",
    "   ‚Ä¢ Teste em cen√°rios cl√≠nicos diversos\n",
    "\n",
    "4. MELHORIAS DO SISTEMA\n",
    "   ‚Ä¢ Implemente detec√ß√£o autom√°tica de refei√ß√µes\n",
    "   ‚Ä¢ Adicione predi√ß√£o de exerc√≠cios\n",
    "   ‚Ä¢ Desenvolva alertas inteligentes\n",
    "\n",
    "5. DOCUMENTA√á√ÉO\n",
    "   ‚Ä¢ Documente achados e insights\n",
    "   ‚Ä¢ Publique resultados (com disclaimers)\n",
    "   ‚Ä¢ Compartilhe com comunidade de pesquisa\n",
    "\n",
    "Para mais informa√ß√µes, consulte a documenta√ß√£o completa\n",
    "do projeto em DESIGN.md e README.md\n",
    "\"\"\")\n",
    "\n",
    "# Script adicional: setup.py para instala√ß√£o\n",
    "SETUP_PY_CONTENT = '''\n",
    "\"\"\"\n",
    "Setup script for Artificial Pancreas System (APS)\n",
    "\n",
    "Para instalar:\n",
    "    pip install -e .\n",
    "\n",
    "Para desenvolvimento:\n",
    "    pip install -e \".[dev]\"\n",
    "\"\"\"\n",
    "\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "with open(\"README.md\", \"r\", encoding=\"utf-8\") as fh:\n",
    "    long_description = fh.read()\n",
    "\n",
    "with open(\"requirements.txt\", \"r\", encoding=\"utf-8\") as fh:\n",
    "    requirements = [line.strip() for line in fh if line.strip() and not line.startswith(\"#\")]\n",
    "\n",
    "setup(\n",
    "    name=\"aps-system\",\n",
    "    version=\"1.0.0\",\n",
    "    author=\"Sistema APS\",\n",
    "    author_email=\"aps@example.com\",\n",
    "    description=\"Sistema de P√¢ncreas Artificial para Simula√ß√£o e Pesquisa\",\n",
    "    long_description=long_description,\n",
    "    long_description_content_type=\"text/markdown\",\n",
    "    url=\"https://github.com/example/aps-system\",\n",
    "    packages=find_packages(where=\"src\"),\n",
    "    package_dir={\"\": \"src\"},\n",
    "    classifiers=[\n",
    "        \"Development Status :: 4 - Beta\",\n",
    "        \"Intended Audience :: Science/Research\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Operating System :: OS Independent\",\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        \"Programming Language :: Python :: 3.10\",\n",
    "        \"Programming Language :: Python :: 3.11\",\n",
    "        \"Topic :: Scientific/Engineering :: Medical Science Apps.\",\n",
    "    ],\n",
    "    python_requires=\">=3.10\",\n",
    "    install_requires=requirements,\n",
    "    extras_require={\n",
    "        \"dev\": [\n",
    "            \"pytest>=7.0.0\",\n",
    "            \"pytest-asyncio>=0.20.0\",\n",
    "            \"black>=22.0.0\",\n",
    "            \"flake8>=5.0.0\",\n",
    "            \"mypy>=0.990\",\n",
    "            \"jupyter>=1.0.0\",\n",
    "            \"notebook>=6.5.0\",\n",
    "        ]\n",
    "    },\n",
    "    entry_points={\n",
    "        \"console_scripts\": [\n",
    "            \"aps-system=main:main\",\n",
    "            \"aps-simulate=examples.run_scenarios:main\",\n",
    "            \"aps-analyze=notebooks.analysis_example:main\",\n",
    "        ],\n",
    "    },\n",
    "    include_package_data=True,\n",
    "    package_data={\n",
    "        \"\": [\"*.yaml\", \"*.json\", \"*.html\", \"*.css\", \"*.js\"],\n",
    "    },\n",
    "    zip_safe=False,\n",
    ")\n",
    "'''\n",
    "\n",
    "# Salvar setup.py\n",
    "with open('setup.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(SETUP_PY_CONTENT)\n",
    "\n",
    "print(\"üì¶ setup.py criado para instala√ß√£o do pacote\")\n",
    "\n",
    "# Script final: Makefile para automa√ß√£o\n",
    "MAKEFILE_CONTENT = '''\n",
    "# Makefile para Sistema de P√¢ncreas Artificial\n",
    "\n",
    ".PHONY: help install install-dev test lint format run-simulation run-tests clean docs\n",
    "\n",
    "help:\n",
    "\t@echo \"Sistema de P√¢ncreas Artificial - Comandos dispon√≠veis:\"\n",
    "\t@echo \"\"\n",
    "\t@echo \"  install        Instalar depend√™ncias b√°sicas\"\n",
    "\t@echo \"  install-dev    Instalar depend√™ncias de desenvolvimento\"\n",
    "\t@echo \"  test           Executar todos os testes\"\n",
    "\t@echo \"  lint           Verificar c√≥digo com linters\"\n",
    "\t@echo \"  format         Formatar c√≥digo\"\n",
    "\t@echo \"  run-simulation Executar simula√ß√£o de exemplo\"\n",
    "\t@echo \"  run-scenarios  Executar cen√°rios de teste\"\n",
    "\t@echo \"  analyze        Executar an√°lise de dados\"\n",
    "\t@echo \"  clean          Limpar arquivos tempor√°rios\"\n",
    "\t@echo \"  docs           Gerar documenta√ß√£o\"\n",
    "\n",
    "install:\n",
    "\tpip install -r requirements.txt\n",
    "\n",
    "install-dev:\n",
    "\tpip install -r requirements.txt\n",
    "\tpip install -e \".[dev]\"\n",
    "\n",
    "test:\n",
    "\tpytest tests/ -v --cov=src --cov-report=html\n",
    "\n",
    "lint:\n",
    "\tflake8 src/ tests/\n",
    "\tmypy src/\n",
    "\n",
    "format:\n",
    "\tblack src/ tests/ examples/\n",
    "\tisort src/ tests/ examples/\n",
    "\n",
    "run-simulation:\n",
    "\tpython src/main.py --mode simulation --duration 24 --acceleration 10\n",
    "\n",
    "run-scenarios:\n",
    "\tpython examples/run_scenarios.py\n",
    "\n",
    "analyze:\n",
    "\tjupyter notebook notebooks/analysis_example.ipynb\n",
    "\n",
    "clean:\n",
    "\tfind . -type f -name \"*.pyc\" -delete\n",
    "\tfind . -type d -name \"__pycache__\" -delete\n",
    "\trm -rf htmlcov/\n",
    "\trm -rf .pytest_cache/\n",
    "\trm -rf .mypy_cache/\n",
    "\trm -rf logs/*.log\n",
    "\trm -rf exports/*.csv\n",
    "\n",
    "docs:\n",
    "\t@echo \"Documenta√ß√£o dispon√≠vel em:\"\n",
    "\t@echo \"  README.md - Guia principal\"\n",
    "\t@echo \"  DESIGN.md - Decis√µes t√©cnicas\"\n",
    "\t@echo \"  docs/ - Documenta√ß√£o detalhada\"\n",
    "\n",
    "docker-build:\n",
    "\tdocker build -t aps-system .\n",
    "\n",
    "docker-run:\n",
    "\tdocker run -p 8000:8000 aps-system\n",
    "\n",
    "# Comandos de seguran√ßa\n",
    "security-check:\n",
    "\t@echo \"‚ö†Ô∏è  VERIFICA√á√ÉO DE SEGURAN√áA:\"\n",
    "\t@echo \"   ‚Ä¢ Sistema apenas para simula√ß√£o\"\n",
    "\t@echo \"   ‚Ä¢ N√ÉO usar em pacientes reais\" \n",
    "\t@echo \"   ‚Ä¢ Valida√ß√£o cl√≠nica necess√°ria\"\n",
    "\t@echo \"   ‚Ä¢ Aprova√ß√£o regulat√≥ria obrigat√≥ria\"\n",
    "\n",
    "# Comandos de backup\n",
    "backup:\n",
    "\tmkdir -p backups/\n",
    "\ttar -czf backups/aps_backup_$(shell date +%Y%m%d_%H%M%S).tar.gz \\\n",
    "\t\tsrc/ tests/ examples/ notebooks/ config.yaml requirements.txt\n",
    "\t@echo \"Backup criado em backups/\"\n",
    "\n",
    "# Comando para publica√ß√£o (apenas ap√≥s valida√ß√£o)\n",
    "publish-research:\n",
    "\t@echo \"üìö ANTES DE PUBLICAR:\"\n",
    "\t@echo \"   ‚úÖ Validar todos os algoritmos\"\n",
    "\t@echo \"   ‚úÖ Revisar disclaimers de seguran√ßa\"\n",
    "\t@echo \"   ‚úÖ Incluir limita√ß√µes do estudo\"\n",
    "\t@echo \"   ‚úÖ Obter aprova√ß√£o de comit√™ de √©tica\"\n",
    "\t@echo \"\"\n",
    "\t@echo \"Para prosseguir com publica√ß√£o de pesquisa:\"\n",
    "\t@echo \"   make security-check && python scripts/prepare_publication.py\"\n",
    "'''\n",
    "\n",
    "# Salvar Makefile\n",
    "with open('Makefile', 'w') as f:\n",
    "    f.write(MAKEFILE_CONTENT)\n",
    "\n",
    "print(\"üîß Makefile criado para automa√ß√£o do projeto\")\n",
    "\n",
    "print(\"\"\"\n",
    "üéâ SISTEMA DE P√ÇNCREAS ARTIFICIAL COMPLETO!\n",
    "\n",
    "O projeto foi criado com sucesso incluindo:\n",
    "\n",
    "üìÅ ESTRUTURA COMPLETA:\n",
    "   ‚úÖ Simulador fisiol√≥gico baseado UVA/Padova\n",
    "   ‚úÖ Controlador PID + Machine Learning h√≠brido\n",
    "   ‚úÖ Sistema de seguran√ßa multicamadas\n",
    "   ‚úÖ Interface web interativa\n",
    "   ‚úÖ API REST e WebSocket\n",
    "   ‚úÖ M√©tricas avan√ßadas de desempenho\n",
    "   ‚úÖ Testes automatizados\n",
    "   ‚úÖ An√°lise de dados em Jupyter\n",
    "   ‚úÖ Documenta√ß√£o completa\n",
    "   ‚úÖ Scripts de exemplo e cen√°rios\n",
    "\n",
    "üöÄ PARA COME√áAR:\n",
    "   1. pip install -r requirements.txt\n",
    "   2. python src/main.py --mode simulation --web\n",
    "   3. Abrir http://localhost:8000\n",
    "   4. Explorar cen√°rios em examples/run_scenarios.py\n",
    "\n",
    "‚ö†Ô∏è  IMPORTANTE:\n",
    "   ‚Ä¢ Sistema EXPERIMENTAL apenas\n",
    "   ‚Ä¢ N√ÉO usar clinicamente\n",
    "   ‚Ä¢ Requer valida√ß√£o e aprova√ß√£o\n",
    "   ‚Ä¢ Consultar README.md para detalhes\n",
    "\n",
    "üî¨ CONTRIBUI√á√ïES:\n",
    "   ‚Ä¢ Testar algoritmos\n",
    "   ‚Ä¢ Melhorar m√©tricas\n",
    "   ‚Ä¢ Adicionar cen√°rios\n",
    "   ‚Ä¢ Validar com dados reais\n",
    "   ‚Ä¢ Otimizar performance\n",
    "\n",
    "Boa pesquisa e desenvolvimento respons√°vel! üß¨üë®‚Äç‚öïÔ∏èüë©‚Äç‚öïÔ∏è\n",
    "\"\"\")\n",
    "\n",
    "# Coment√°rio final com instru√ß√µes de uso do notebook\n",
    "\"\"\"\n",
    "INSTRU√á√ïES PARA USO DESTE NOTEBOOK:\n",
    "\n",
    "1. CONFIGURA√á√ÉO INICIAL:\n",
    "   - Instalar depend√™ncias: pip install -r requirements.txt\n",
    "   - Verificar dados dispon√≠veis ou usar dados sint√©ticos\n",
    "   - Configurar par√¢metros no in√≠cio do notebook\n",
    "\n",
    "2. EXECU√á√ÉO:\n",
    "   - Executar c√©lulas sequencialmente\n",
    "   - Modificar par√¢metros conforme necess√°rio  \n",
    "   - Salvar gr√°ficos e resultados importantes\n",
    "\n",
    "3. AN√ÅLISE CUSTOMIZADA:\n",
    "   - Adaptar fun√ß√µes para seus dados espec√≠ficos\n",
    "   - Adicionar m√©tricas personalizadas\n",
    "   - Criar visualiza√ß√µes espec√≠ficas\n",
    "\n",
    "4. EXPORTA√á√ÉO:\n",
    "   - Usar fun√ß√µes de exporta√ß√£o para relat√≥rios\n",
    "   - Salvar gr√°ficos em alta resolu√ß√£o\n",
    "   - Gerar relat√≥rios HTML para compartilhamento\n",
    "\n",
    "5. PR√ìXIMOS PASSOS:\n",
    "   - Integrar com pipeline de ML\n",
    "   - Automatizar an√°lises peri√≥dicas\n",
    "   - Criar dashboards em tempo real\n",
    "\n",
    "‚ö†Ô∏è LEMBRETE IMPORTANTE:\n",
    "Este notebook √© para an√°lise de dados de SIMULA√á√ÉO apenas.\n",
    "Nunca usar resultados para decis√µes cl√≠nicas reais sem\n",
    "valida√ß√£o m√©dica adequada e aprova√ß√£o regulat√≥ria.\n",
    "\"\"\"# notebooks/analysis_example.ipynb - Notebook de An√°lise\n",
    "\"\"\"\n",
    "Notebook Jupyter para an√°lise avan√ßada do Sistema de P√¢ncreas Artificial\n",
    "\n",
    "Este notebook demonstra:\n",
    "1. Carregamento e preprocessamento de dados de simula√ß√£o\n",
    "2. An√°lise de m√©tricas de desempenho\n",
    "3. Visualiza√ß√µes interativas\n",
    "4. Compara√ß√µes entre diferentes configura√ß√µes\n",
    "5. An√°lise de padr√µes temporais\n",
    "6. Relat√≥rios automatizados\n",
    "\"\"\"\n",
    "\n",
    "# C√©lula 1: Imports e configura√ß√£o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.sub"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
